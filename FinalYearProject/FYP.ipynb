{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19173,"status":"ok","timestamp":1715950928584,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"},"user_tz":-60},"id":"2iEFh1PQG-Hz","outputId":"900fbfb5-9a4f-4ece-f4ea-dff43f8ce339"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6011,"status":"ok","timestamp":1715950934592,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"},"user_tz":-60},"id":"q-ke0C07-6Mt","outputId":"0248a34e-52af-4f32-873c-b77aa2f01d46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/433.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/433.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.11.1\n"]}],"source":["pip install emoji"]},{"cell_type":"markdown","metadata":{"id":"dNCSwObwflKq"},"source":["# Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AQ7VMocjfjv7","executionInfo":{"status":"ok","timestamp":1715950940290,"user_tz":-60,"elapsed":5702,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["import numpy as np\n","import emoji\n","import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import RobertaTokenizer, RobertaModel\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"MAJiinB0hPWT","executionInfo":{"status":"ok","timestamp":1715950940291,"user_tz":-60,"elapsed":16,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"ELrfvD_QfplY"},"source":["# Global Variables"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4beTs0iXfszN","executionInfo":{"status":"ok","timestamp":1715950940291,"user_tz":-60,"elapsed":15,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["training_data_dir = \"/content/drive/MyDrive/Year3Project/Data/EmojifyData/train.txt\"\n","test_data_dir = \"/content/drive/MyDrive/Year3Project/Data/EmojifyData/test.txt\"\n","TRAIN_SIZE = 50000\n","TEST_SIZE = 5000\n","TRAIN_BATCH_SIZE = 8\n","TEST_BATCH_SIZE = 1\n","LEARNING_RATE = 1e-05"]},{"cell_type":"markdown","metadata":{"id":"to8MJndP-oWq"},"source":["# Get Mapping"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jCbvYlXD_Ty-","executionInfo":{"status":"ok","timestamp":1715950940291,"user_tz":-60,"elapsed":15,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["def simple_tweet_reader(dir):\n","  text = []\n","  labels = []\n","  for line in open(dir):\n","    if len(line) > 1:\n","      words = line.split()\n","      text.append(''.join(words[0:-1]))\n","      labels.append(words[-1])\n","      if words[0] == \"<STOP>\":\n","        yield np.column_stack((text, labels))\n","        text = []\n","        labels = []"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JQ1d7sSX_XT7","executionInfo":{"status":"ok","timestamp":1715950940292,"user_tz":-60,"elapsed":16,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["def get_class_mapping(tweets):\n","  mapping = {}\n","  count = 0\n","  for tweet in tweets:\n","    for label in tweet[:,1]:\n","      if label != 'O':\n","        if label not in mapping:\n","          mapping[label] = count\n","          count = count + 1\n","\n","  return mapping"]},{"cell_type":"markdown","metadata":{"id":"ibiqaeMDyKJC"},"source":["Following code is ran once and values hard coded"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1715950940292,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"},"user_tz":-60},"id":"KuSFPnN_-uPp","outputId":"d4a12022-fb13-427e-beb0-5fdc7714fdaf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n\\ntweets = simple_tweet_reader(training_data_dir)\\n\\nmapping = get_class_mapping(tweets)\\n\\nmapping\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}],"source":["\"\"\"\n","\n","tweets = simple_tweet_reader(training_data_dir)\n","\n","mapping = get_class_mapping(tweets)\n","\n","mapping\n","\n","\"\"\""]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1j2-2tScAYI2","executionInfo":{"status":"ok","timestamp":1715950940292,"user_tz":-60,"elapsed":7,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["mapping = {':face_with_tears_of_joy:': 0,\n"," ':weary_face:': 1,\n"," ':purple_heart:': 2,\n"," ':party_popper:': 3,\n"," ':speaking_head:': 4,\n"," ':sparkles:': 5,\n"," ':clapping_hands:': 6,\n"," ':loudly_crying_face:': 7,\n"," ':smiling_face_with_heart-eyes:': 8,\n"," ':person_shrugging:': 9,\n"," ':female_sign:': 10,\n"," ':fire:': 11,\n"," ':person_facepalming:': 12,\n"," ':male_sign:': 13,\n"," ':red_heart:': 14,\n"," ':hundred_points:': 15,\n"," ':raising_hands:': 16,\n"," ':trophy:': 17,\n"," ':beaming_face_with_smiling_eyes:': 18,\n"," ':backhand_index_pointing_down:': 19,\n"," ':two_hearts:': 20,\n"," ':heart_suit:': 21,\n"," ':skull:': 22,\n"," ':thumbs_up:': 23,\n"," ':folded_hands:': 24,\n"," ':flexed_biceps:': 25,\n"," ':face_blowing_a_kiss:': 26,\n"," ':smiling_face:': 27,\n"," ':face_with_rolling_eyes:': 28,\n"," ':crying_face:': 29,\n"," ':police_car_light:': 30,\n"," ':OK_hand:': 31,\n"," ':blue_heart:': 32,\n"," ':thinking_face:': 33,\n"," ':winking_face:': 34,\n"," ':flushed_face:': 35,\n"," ':white_heavy_check_mark:': 36,\n"," ':smiling_face_with_sunglasses:': 37,\n"," ':double_exclamation_mark:': 38,\n"," ':smiling_face_with_smiling_eyes:': 39,\n"," ':backhand_index_pointing_right:': 40,\n"," ':collision:': 41,\n"," ':rolling_on_the_floor_laughing:': 42,\n"," ':yellow_heart:': 43,\n"," ':glowing_star:': 44,\n"," ':right_arrow:': 45,\n"," ':heavy_check_mark:': 46,\n"," ':eyes:': 47,\n"," ':sparkling_heart:': 48}"]},{"cell_type":"markdown","metadata":{"id":"WzT-Ximo0_4J"},"source":["# Get Data"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"byqBD5guNRY6","executionInfo":{"status":"ok","timestamp":1715950940292,"user_tz":-60,"elapsed":7,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["class Tweet():\n","  def __init__(self, text, labels):\n","    self.text = text\n","    self.labels = labels\n","\n","  def duplicate_tweet(self):\n","    labels = set(self.labels)\n","    labels.discard(-1)\n","    phrases = ' '.join(self.text)\n","    phrases = np.repeat(phrases, len(labels))\n","    return np.column_stack((phrases, np.array(list(labels))))\n","\n","  def split_on_emoji(self):\n","    phrases = []\n","    labels = []\n","    text = []\n","    for word, label in zip(self.text, self.labels):\n","      text.append(word)\n","      if label != -1:\n","        if len(text) > 2:\n","          phrases.append(' '.join(text))\n","          labels.append(label)\n","        text = []\n","    return np.column_stack((phrases, labels))\n","\n","  def test_tweet(self):\n","    labels = set(self.labels)\n","    labels.discard(-1)\n","    return (' '.join(self.text), np.array(list(labels)))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Ks-C4KUmoBjj","executionInfo":{"status":"ok","timestamp":1715950940292,"user_tz":-60,"elapsed":7,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["def tweet_reader(dir, mapping):\n","  text = []\n","  labels = []\n","  for line in open(dir):\n","    if len(line) > 1:\n","      words = line.split()\n","      if words[0] == \"<START>\" or words[0] == \"<STOP>\":\n","        text.append('')\n","      else:\n","        text.append(''.join(words[0:-1]))\n","      label = words[-1]\n","      if label == 'O':\n","        label = -1;\n","      else:\n","        label = mapping[label]\n","      labels.append(label)\n","      if words[0] == \"<STOP>\":\n","        yield Tweet(np.array(text), np.array(labels))\n","        text = []\n","        labels = []\n","\n","def duplicate_tweet_reader(tweets):\n","  for tweet in tweets[0]:\n","    vals = tweet.duplicate_tweet()\n","    for val in vals:\n","      yield val\n","\n","def split_on_emoji_reader(tweets):\n","  for tweet in tweets[0]:\n","    vals = tweet.split_on_emoji()\n","    for val in vals:\n","      yield val\n","\n","def test_tweet_reader(tweets):\n","  for tweet in tweets[0]:\n","    val = tweet.test_tweet()\n","    yield val"]},{"cell_type":"markdown","metadata":{"id":"YEGJlg2BKTyJ"},"source":["https://www.kaggle.com/datasets/rexhaif/emojifydata-en?resource=download\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"S08_12o13zgK","executionInfo":{"status":"ok","timestamp":1715950940292,"user_tz":-60,"elapsed":6,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[],"source":["def summary(tweets):\n","  labels_counts = {}\n","  count = 0\n","  for tweet in tweets:\n","    count = count + 1\n","\n","    for label in tweet.labels:\n","      if label != -1:\n","        labels_counts[label] = labels_counts.get(label, 0) + 1\n","\n","  print(f\"Number of Tweets: {count}\")\n","  print(f\"Number of Emojis (classes) {len(labels_counts)}\")\n","  print(f\"Emojis: {labels_counts}\")\n"]},{"cell_type":"code","source":["tweets = tweet_reader(training_data_dir, mapping)\n","\n","summary(tweets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-9-fAxNpB-A","executionInfo":{"status":"ok","timestamp":1715951133859,"user_tz":-60,"elapsed":126679,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"034d9ea1-65fc-4b27-d1d5-a67b777e1c63"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Tweets: 6567625\n","Number of Emojis (classes) 49\n","Emojis: {0: 1289713, 1: 172054, 2: 99114, 3: 108384, 4: 74819, 5: 172604, 6: 232379, 7: 505359, 8: 369943, 9: 167083, 10: 295265, 11: 436422, 12: 145759, 13: 218984, 14: 736664, 15: 137218, 16: 168722, 17: 75797, 18: 68810, 19: 81310, 20: 169041, 21: 107812, 22: 91693, 23: 107742, 24: 224002, 25: 102611, 26: 97316, 27: 71107, 28: 105933, 29: 59575, 30: 149174, 31: 79765, 32: 89699, 33: 135281, 34: 78206, 35: 62435, 36: 107182, 37: 76249, 38: 125194, 39: 149645, 40: 182706, 41: 95370, 42: 116567, 43: 57581, 44: 69093, 45: 73906, 46: 92821, 47: 121906, 48: 84255}\n"]}]},{"cell_type":"code","source":["tweets = tweet_reader(test_data_dir, mapping)\n","\n","summary(tweets)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MICTsjfLpgAe","executionInfo":{"status":"ok","timestamp":1715951174652,"user_tz":-60,"elapsed":40794,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"09016727-32f4-44e0-92f0-77ec95835504"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Tweets: 2052383\n","Number of Emojis (classes) 49\n","Emojis: {48: 26237, 0: 401715, 24: 70686, 4: 23137, 21: 33752, 40: 57364, 31: 24852, 12: 45441, 13: 68988, 7: 157650, 45: 23192, 1: 53689, 9: 52302, 10: 92027, 34: 23922, 29: 18655, 20: 52439, 5: 54333, 35: 19387, 2: 31141, 32: 28187, 46: 28768, 16: 53025, 23: 33976, 6: 73743, 14: 232276, 11: 136725, 3: 33968, 25: 31760, 8: 115349, 43: 17910, 33: 42433, 22: 28935, 30: 46254, 19: 25428, 38: 38265, 26: 30620, 39: 46719, 36: 33936, 44: 21227, 28: 33088, 47: 38392, 27: 21921, 15: 42740, 42: 36444, 18: 21442, 41: 30121, 37: 24138, 17: 23744}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQ-tMgELEmF4"},"outputs":[],"source":["class emojiDataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len=256):\n","    self.tokenizer = tokenizer\n","    self.data = dataframe\n","    self.text = dataframe[\"Tweet\"]\n","    self.labels = dataframe[\"Label\"]\n","    self.max_length = max_len\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, index):\n","    inputs = self.tokenizer.encode_plus(\n","            self.text[index],\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","    ids = inputs['input_ids']\n","    mask = inputs['attention_mask']\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        'ids': torch.tensor(ids, dtype=torch.long),\n","        'mask': torch.tensor(mask, dtype=torch.long),\n","        'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","        'targets': torch.tensor(self.labels[index], dtype=torch.float)\n","      }"]},{"cell_type":"code","source":["class testDataset(Dataset):\n","  def __init__(self, dataframe, tokenizer, max_len=256):\n","    self.tokenizer = tokenizer\n","    self.data = dataframe\n","    self.text = dataframe[\"Tweet\"]\n","    self.labels = dataframe[\"Label\"]\n","    self.max_length = max_len\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, index):\n","    inputs = self.tokenizer.encode_plus(\n","            self.text[index],\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","    ids = inputs['input_ids']\n","    mask = inputs['attention_mask']\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    return {\n","        'ids': torch.tensor(ids, dtype=torch.long),\n","        'mask': torch.tensor(mask, dtype=torch.long),\n","        'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","        'targets': torch.tensor(self.labels[index], dtype=torch.float)\n","      }"],"metadata":{"id":"DXyM_yvpZ4gw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tweets = tweet_reader(training_data_dir, mapping)\n","train_data = pd.DataFrame(data=tweets)\n","summary(train_data[0])\n","train_data = train_data.sample(TRAIN_SIZE)\n","summary(train_data[0])\n","\n","tweets = tweet_reader(test_data_dir, mapping)\n","test_data = pd.DataFrame(data=tweets)\n","summary(test_data[0])\n","test_data = test_data.sample(TEST_SIZE)\n","summary(test_data[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0LAYJBqwk8l","executionInfo":{"status":"ok","timestamp":1714386670686,"user_tz":-60,"elapsed":288492,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"1b9503a1-4c88-41df-867e-a15ff73056e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Tweets: 6567625\n","Number of Emojis (classes) 49\n","Emojis: {0: 1289713, 1: 172054, 2: 99114, 3: 108384, 4: 74819, 5: 172604, 6: 232379, 7: 505359, 8: 369943, 9: 167083, 10: 295265, 11: 436422, 12: 145759, 13: 218984, 14: 736664, 15: 137218, 16: 168722, 17: 75797, 18: 68810, 19: 81310, 20: 169041, 21: 107812, 22: 91693, 23: 107742, 24: 224002, 25: 102611, 26: 97316, 27: 71107, 28: 105933, 29: 59575, 30: 149174, 31: 79765, 32: 89699, 33: 135281, 34: 78206, 35: 62435, 36: 107182, 37: 76249, 38: 125194, 39: 149645, 40: 182706, 41: 95370, 42: 116567, 43: 57581, 44: 69093, 45: 73906, 46: 92821, 47: 121906, 48: 84255}\n","Number of Tweets: 50000\n","Number of Emojis (classes) 49\n","Emojis: {42: 858, 11: 3276, 24: 1592, 13: 1683, 8: 2827, 33: 1039, 0: 9926, 37: 565, 23: 824, 25: 749, 7: 3748, 40: 1365, 35: 490, 16: 1331, 12: 1099, 41: 671, 28: 835, 39: 1221, 48: 610, 29: 451, 2: 746, 26: 726, 30: 1105, 27: 523, 19: 653, 14: 5404, 44: 555, 45: 599, 18: 536, 34: 621, 5: 1377, 22: 724, 1: 1293, 31: 535, 47: 938, 36: 807, 17: 551, 15: 1063, 9: 1233, 3: 837, 20: 1270, 32: 720, 4: 534, 10: 2205, 46: 773, 38: 958, 21: 872, 6: 1879, 43: 406}\n","Number of Tweets: 6567625\n","Number of Emojis (classes) 49\n","Emojis: {0: 1289713, 1: 172054, 2: 99114, 3: 108384, 4: 74819, 5: 172604, 6: 232379, 7: 505359, 8: 369943, 9: 167083, 10: 295265, 11: 436422, 12: 145759, 13: 218984, 14: 736664, 15: 137218, 16: 168722, 17: 75797, 18: 68810, 19: 81310, 20: 169041, 21: 107812, 22: 91693, 23: 107742, 24: 224002, 25: 102611, 26: 97316, 27: 71107, 28: 105933, 29: 59575, 30: 149174, 31: 79765, 32: 89699, 33: 135281, 34: 78206, 35: 62435, 36: 107182, 37: 76249, 38: 125194, 39: 149645, 40: 182706, 41: 95370, 42: 116567, 43: 57581, 44: 69093, 45: 73906, 46: 92821, 47: 121906, 48: 84255}\n","Number of Tweets: 5000\n","Number of Emojis (classes) 49\n","Emojis: {7: 416, 1: 123, 12: 105, 10: 192, 0: 990, 14: 520, 34: 52, 8: 286, 11: 348, 42: 72, 39: 118, 29: 58, 2: 78, 3: 109, 28: 69, 37: 62, 32: 91, 20: 140, 6: 149, 26: 74, 44: 36, 19: 68, 21: 73, 35: 46, 16: 110, 22: 68, 45: 75, 24: 155, 9: 124, 15: 103, 17: 56, 23: 59, 13: 174, 40: 142, 30: 141, 27: 47, 43: 40, 33: 113, 47: 81, 41: 78, 46: 64, 38: 72, 36: 91, 5: 137, 18: 49, 48: 58, 4: 45, 25: 82, 31: 60}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSlQVVq7Px-J"},"outputs":[],"source":["tweets = split_on_emoji_reader(train_data)\n","\n","train = pd.DataFrame(data=tweets, columns=(\"Tweet\", \"Label\"))\n","train[\"Label\"] = train[\"Label\"].astype('int32')\n","\n","tweets = test_tweet_reader(test_data)\n","\n","test = pd.DataFrame(data=tweets, columns=(\"Tweet\", \"Label\"))\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","split_train_set = emojiDataset(train, tokenizer)\n","split_test_set = emojiDataset(test, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_38XKCLHywV"},"outputs":[],"source":["tweets = duplicate_tweet_reader(train_data)\n","\n","train = pd.DataFrame(data=tweets, columns=(\"Tweet\", \"Label\"))\n","train[\"Label\"] = train[\"Label\"].astype('int32')\n","\n","tweets = test_tweet_reader(test_data)\n","\n","test = pd.DataFrame(data=tweets, columns=(\"Tweet\", \"Label\"))\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n","\n","duplicate_train_set = emojiDataset(train, tokenizer)\n","duplicate_test_set = emojiDataset(test, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qgao62UFJpY-"},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': TEST_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","split_train_loader = DataLoader(split_train_set, **train_params)\n","split_test_loader = DataLoader(split_test_set, **test_params)\n","duplicate_train_loader = DataLoader(duplicate_train_set, **train_params)\n","duplicate_test_loader = DataLoader(duplicate_test_set, **test_params)"]},{"cell_type":"markdown","metadata":{"id":"nfjQxnJp1Gjm"},"source":["# Get Model"]},{"cell_type":"markdown","metadata":{"id":"R68egHC09zxh"},"source":["https://colab.research.google.com/drive/1Ek5PxTLAx6u2yQiDzVCVZpNNlno6jwaD#scrollTo=c3Q9NDdmqEyo"]},{"cell_type":"markdown","metadata":{"id":"MQqQc7d9qTWa"},"source":["https://huggingface.co/cardiffnlp/twitter-roberta-base-emoji"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQym-XrqgIxu"},"outputs":[],"source":["class EmojiModel(torch.nn.Module):\n","  def __init__(self):\n","    super(EmojiModel, self).__init__()\n","    self.roberta_base = RobertaModel.from_pretrained(\"roberta-base\")\n","    # roberta_base has 768 output nodes\n","    self.pre_classifier = torch.nn.Linear(768, 768)\n","    self.dropout = torch.nn.Dropout(0.3)\n","    self.classifier = torch.nn.Linear(768, 49)\n","\n","  def forward(self, input_ids, attention_mask, token_type_ids):\n","    output = self.roberta_base(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","    # output is the final hidden state and pooling output for each token, I only need the final hidden state\n","    output = output[0][:,0]\n","    output = self.pre_classifier(output)\n","    output = torch.nn.ReLU()(output)\n","    output = self.dropout(output)\n","    output = self.classifier(output)\n","    return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1714386678624,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"},"user_tz":-60},"id":"B6xDrorimd5Q","outputId":"6989ffd7-c559-4072-b1d0-102a8fb9e110"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["EmojiModel(\n","  (roberta_base): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=49, bias=True)\n",")"]},"metadata":{},"execution_count":149}],"source":["split_model = EmojiModel()\n","split_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q7OoCYoFLAeU"},"outputs":[],"source":["loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  split_model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPNQtB_Ged-Y"},"outputs":[],"source":["def accuracy(outputs, target):\n","  _, preds = torch.max(outputs, dim=1)\n","  return (preds==target).sum().item()"]},{"cell_type":"code","source":["def accuracy_at_5(outputs, target):\n","  _, preds = torch.topk(outputs, 5, dim=1)\n","  return sum((target[i] in preds[i]) for i in range(len(target)))"],"metadata":{"id":"KN0yQ71TWJ8H"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bpi3Ejc_ehPo","outputId":"19144fd9-6958-49b8-d84a-38076e60f55d","executionInfo":{"status":"ok","timestamp":1714387352296,"user_tz":-60,"elapsed":673676,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","2it [00:00, 10.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 5000 steps: 3.9767966270446777\n"]},{"output_type":"stream","name":"stderr","text":["5002it [08:49,  9.41it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 5000 steps: 3.8904553523327774\n"]},{"output_type":"stream","name":"stderr","text":["6359it [11:13,  9.44it/s]\n"]}],"source":["tr_loss = 0\n","nb_tr_steps = 0\n","split_model.train()\n","for _,data in tqdm(enumerate(split_train_loader, 0)):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.long)\n","\n","    outputs = split_model(ids, mask, token_type_ids)\n","    loss = loss_function(outputs, targets)\n","    tr_loss += loss.item()\n","\n","    nb_tr_steps += 1\n","\n","    if _%5000==0:\n","        loss_step = tr_loss/nb_tr_steps\n","        print(f\"Training Loss per 5000 steps: {loss_step}\")\n","\n","    optimizer.zero_grad()\n","    loss.backward()"]},{"cell_type":"code","source":["split_model.eval()\n","n_correct = 0; n_correct_5 = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n","with torch.no_grad():\n","    for _, data in tqdm(enumerate(split_test_loader, 0)):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","        outputs = split_model(ids, mask, token_type_ids)\n","        n_correct += accuracy(outputs.data, targets)\n","        n_correct_5 += accuracy_at_5(outputs.data, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","\n","        if _%5000==0:\n","            accu_step = (n_correct*100)/nb_tr_examples\n","            print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","accu = (n_correct*100)/nb_tr_examples\n","accu_5 = (n_correct_5*100)/nb_tr_examples\n","print(f\"Accuracy: {accu}\")\n","print(f\"Accuracy at 5: {accu_5}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bAkQKDlegOM","executionInfo":{"status":"ok","timestamp":1714388153441,"user_tz":-60,"elapsed":399,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"46c6c551-7e6a-457b-b673-bc1f361c2255"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 29\n","Accuracy at 5: 41\n"]}]},{"cell_type":"code","source":["duplicate_model = EmojiModel()\n","duplicate_model.to(device)"],"metadata":{"id":"Faz1URqv8VF2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714388193889,"user_tz":-60,"elapsed":1319,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"cb81c0be-a5f6-44fa-b1f9-e6423439b78e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["EmojiModel(\n","  (roberta_base): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=49, bias=True)\n",")"]},"metadata":{},"execution_count":156}]},{"cell_type":"code","source":["tr_loss = 0\n","nb_tr_steps = 0\n","duplicate_model.train()\n","for _,data in tqdm(enumerate(duplicate_train_loader, 0)):\n","    ids = data['ids'].to(device, dtype = torch.long)\n","    mask = data['mask'].to(device, dtype = torch.long)\n","    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","    targets = data['targets'].to(device, dtype = torch.long)\n","\n","    outputs = duplicate_model(ids, mask, token_type_ids)\n","    loss = loss_function(outputs, targets)\n","    tr_loss += loss.item()\n","\n","    nb_tr_steps += 1\n","\n","    if _%5000==0:\n","        loss_step = tr_loss/nb_tr_steps\n","        print(f\"Training Loss per 5000 steps: {loss_step}\")\n","\n","    optimizer.zero_grad()\n","    loss.backward()"],"metadata":{"id":"9SMehLRVd_Jn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714388966454,"user_tz":-60,"elapsed":772201,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"c5be5201-ce75-42f7-bd9a-1a3c3292ec96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","2it [00:00, 10.18it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 5000 steps: 3.938277244567871\n"]},{"output_type":"stream","name":"stderr","text":["5002it [08:58,  9.21it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Loss per 5000 steps: 3.9118153334283705\n"]},{"output_type":"stream","name":"stderr","text":["7168it [12:52,  9.28it/s]\n"]}]},{"cell_type":"code","source":["duplicate_model.eval()\n","n_correct = 0; n_correct_5 = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n","with torch.no_grad():\n","    for _, data in tqdm(enumerate(duplicate_test_loader, 0)):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","        outputs = duplicate_model(ids, mask, token_type_ids)\n","        n_correct += accuracy(outputs.data, targets)\n","        n_correct_5 += accuracy_at_5(outputs.data, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples+=targets.size(0)\n","\n","        if _%5000==0:\n","            accu_step = (n_correct*100)/nb_tr_examples\n","            print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n","accu = (n_correct*100)/nb_tr_examples\n","accu_5 = (n_correct_5 *100)/nb_tr_examples\n","print(f\"Accuracy: {accu}\")\n","print(f\"Accuracy at 5: {accu_5}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hivQ6glhf1MM","executionInfo":{"status":"ok","timestamp":1714388966454,"user_tz":-60,"elapsed":11,"user":{"displayName":"Sean Carey","userId":"17323765725562851333"}},"outputId":"c9cd0527-bd5b-4d13-d31b-b84e1c47baad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 36\n","Accuracy at 5: 47\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","provenance":[],"machine_shape":"hm","mount_file_id":"1jGAopqcPyZ12IKLISc34_4J9XrFWAHje","authorship_tag":"ABX9TyMpsI/+n1usqBzl7HlaLGtA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}